<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ggplot2]]></title>
    <url>%2Fxiaoyue.github.io%2F2019%2F08%2F10%2Fggplot2%2F</url>
    <content type="text"><![CDATA[123library(ggplot2)library(plotly)library(lubridate) #处理时间序列的包 基本上通过ggplot2包建立图形，使用plotly包进行渲染。博客不支持plotly渲染，可自己线下运行。 关于ggplot2可浏览：RStudio Cheat Sheets 关于plotly可浏览：showcase_plotly 单变量条形图discrete x 12345#二者等价,方法不同。本质对原始数据集进行统计计数#geom_barp&lt;-ggplot(data=diamonds,mapping = aes(x=cut))+ geom_bar() #alpha, color, fill, linetype, size, weightggplotly(p) 1234#stat_count,y=..count..换成y=..prop..展示比例p&lt;-ggplot(data=diamonds,mapping = aes(x=cut,y=..count..,group=1))+ stat_count()ggplotly(p) 汇总好的数据集,discrete x,continuous y,应该放到双变量，放在此处方便对比 1234567891011#对分类变量已汇总完毕，生成双变量的数据集，展示条形图#生成汇总好的数据集,discrete x,continuous ydemo&lt;-tibble::tribble( ~a,~b, "bar_1", 20, "bar_2", 30, "bar_3", 40)p&lt;-ggplot(data=demo,mapping = aes(x=a,y=b))+ geom_bar(stat='identity')ggplotly(p) 直方图continuous x 123p&lt;-ggplot(data=mpg,mapping = aes(x=hwy))+ geom_histogram(binwidth = 5) #组距为5ggplotly(p) “ 概率密度图continuous x 1234p&lt;-ggplot(data=mpg,mapping = aes(x=hwy))+ geom_density(kernel='gaussian',color='blue') #alpha, color, fill, group, linetype, size, weightggplotly(p) 面积图continuous x 1234p&lt;-ggplot(data=mpg,mapping = aes(x=hwy))+ geom_area(stat = 'bin')#alpha, color, fill, linetype, sizeggplotly(p) 双变量连续与连续散点图continuous x , continuous y 1234#图形属性双参数双变量的散点图p&lt;-ggplot(data = mpg,mapping = aes(x=displ,y=hwy))+ geom_point(color='red')ggplotly(p) 1234#图形属性三参数双变量的散点图p&lt;-ggplot(data = mpg,mapping = aes(x=displ,y=hwy,color=displ&lt;5))+ geom_point()ggplotly(p) 平滑曲线continuous x , continuous y 1234#平滑曲线p&lt;-ggplot(data = mpg,mapping=aes(x=displ,y=hwy))+ geom_smooth(color='red') #可在几何图形添加参数se=false，去掉置信区间ggplotly(p) 1234#线性回归拟合平滑曲线p&lt;-ggplot(data = mpg,mapping=aes(x=displ,y=hwy))+ geom_smooth(color='red',method = lm)ggplotly(p) 12345#散点图拟合平滑曲线p&lt;-ggplot(data = mpg,mapping = aes(x=displ,y=hwy))+ geom_point()+ geom_smooth(color='red')ggplotly(p) 标签图continuous x , continuous y 12345#类似构建一个散点图，但是，根据参数aes(label=cty)声明一个标签，显示标签值，并在标签值添加矩形。标签可不是xy变量中的。p&lt;-ggplot(data=mpg,mapping = aes(x=cty,y=hwy))+ geom_label(aes(label=displ),nudge_x = 1,nudge_y = 1,check_overlap=T)## Warning: Ignoring unknown parameters: check_overlapp 标签图continuous x , continuous y 12345#类似构建一个散点图，但是，根据参数aes(label=cty)声明一个标签，显示标签值，标签可不是xy变量中的。与geom_label图的区别是没有矩形。p&lt;-ggplot(data=mpg,mapping = aes(x=cty,y=hwy))+ geom_text(aes(label=displ),nudge_x = 1,nudge_y = 1,check_overlap=T)#check_overlap=T避免字体重叠p 等高线图continuous x , continuous y 1234p&lt;-ggplot(data=diamonds,mapping = aes(x=carat,y=price))+ geom_density2d()#alpha, colour, group, linetype, sizep 离散与连续箱图discrete x,continuous y 1234p&lt;-ggplot(data = mpg,mapping = aes(x=class,y=hwy))+ geom_boxplot()#lower, middle, upper,ymax, ymin, alpha, color, fill, group, linetype,shape, size, weightggplotly(p) 类似条形图的图discrete x,continuous y 1234p&lt;-ggplot(data = mpg,mapping = aes(x=class,y=hwy))+ geom_col()#alpha, color, fill, group,linetype, sizeggplotly(p) 折线图discrete x,continuous y 123456789Year &lt;- year(seq(from = as.Date('2006-01-01'),to = as.Date('2015-01-01'),by ='year'))Weight &lt;- c(23,35,43,57,60,62,63,66,61,62)df &lt;- data.frame(Year = Year, Weight = Weight)p&lt;-ggplot(data = df, mapping = aes(x = factor(Year), y = Weight, group = 1)) + geom_line()+ geom_point()+ xlab('Year')ggplotly(p) 离散与离散计数图discrete x,discrete y 1234p&lt;-ggplot(diamonds, aes(cut, color))+ geom_count()#alpha, color, fill, shape,size, strokeggplotly(p) 三变量散点图continuous x,continuous y,discrete color/shape/size/alpha 1234#颜色分类p&lt;-ggplot(data = mpg,mapping = aes(x=displ,y=hwy,color=class))+ geom_point()ggplotly(p) 1234#形状分类p&lt;-ggplot(data = mpg,mapping = aes(x=displ,y=hwy,shape=class))+ geom_point()ggplotly(p) 1234#大小分类p&lt;-ggplot(data = mpg,mapping = aes(x=displ,y=hwy,size=class))+ geom_point()ggplotly(p) 1234#透明度分类p&lt;-ggplot(data = mpg,mapping = aes(x=displ,y=hwy,alpha=class))+ geom_point()ggplotly(p) 平滑曲线continuous x,continuous y,discrete color/shape/size/alpha 1234#颜色分类p&lt;-ggplot(data = mpg,mapping = aes(x=displ,y=hwy,color=class))+ geom_smooth()ggplotly(p) 1234#形状分类p&lt;-ggplot(data = mpg,mapping = aes(x=displ,y=hwy,shape=class))+ geom_smooth()ggplotly(p) 1234#大小分类p&lt;-ggplot(data = mpg,mapping = aes(x=displ,y=hwy,size=class))+ geom_smooth()ggplotly(p) 1234#透明度分类p&lt;-ggplot(data = mpg,mapping = aes(x=displ,y=hwy,alpha=class))+ geom_smooth()ggplotly(p) 等高线图1234seals$z &lt;- with(seals, sqrt(delta_long^2 + delta_lat^2))p &lt;- ggplot(seals, aes(long, lat))+ geom_contour(aes(z = z))p]]></content>
      <categories>
        <category>ggplot</category>
      </categories>
      <tags>
        <tag>R语言</tag>
        <tag>ggplot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[构建填充图及系统规则]]></title>
    <url>%2Fxiaoyue.github.io%2F2019%2F08%2F09%2Fmap%2F</url>
    <content type="text"><![CDATA[构建填充图1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465library(baidumap)library(REmap)###########################绘制填充图##################################第一步：根据具体地址的经纬度获取省份名称#####data&lt;-read.csv(file = &quot;E:/jingwei/队列经纬度.csv&quot;,sep=&quot;,&quot;,header = TRUE)options(baidumap.key = &quot;o19PIiEcPHfWKstH1jONtO7mw2ntn8cT&quot;)#提取具体地址经纬度#jw_data&lt;-data[,c(&quot;经度1&quot;,&quot;纬度1&quot;)]#定义函数，提取省份，去掉省、市、自治区等，REmap识别不了#getpro&lt;-function(x)&#123; a1&lt;-getLocation(x,output=&apos;json&apos;,formatted=F) pro&lt;-fromJSON(a1)$result$addressComponent$province pro1&lt;-gsub(&apos;省|市|自治区|壮族|维吾尔&apos;,&apos;&apos;,pro) return(pro1)&#125;#按照条件对具体地址经纬度，提取省份#pro&lt;-apply(jw_data[1:10,],MARGIN = 1,getpro)#switch(1,1:2000,2001:5000,5001:8000,8001:11000,11001:14000)##switch(1,1:3000,3001:7000,7001:12000)#res&lt;-c()for(i in 1:3)&#123; if(i==1)&#123; options(baidumap.key = &quot;o19PIiEcPHfWKstH1jONtO7mw2ntn8cT&quot;) aa&lt;-switch(i,1:3000,3001:7000,7001:12000) pro&lt;-apply(jw_data[aa,],MARGIN = 1,getpro) res[aa]&lt;-pro &#125; else if(i==2)&#123; options(baidumap.key = &quot;134db1b9cf1f1f2b4427210932b34dcb&quot;) aa&lt;-switch(i,1:3000,3001:7000,7001:12000) pro&lt;-apply(jw_data[aa,],MARGIN = 1,getpro) res[aa]&lt;-pro &#125; else &#123; options(baidumap.key = &quot;5Rws6aTv40TmiIupfX93COOfyajQ5ZZp&quot;) aa&lt;-switch(i,1:3000,3001:7000,7001:12000) pro&lt;-apply(jw_data[aa,],MARGIN = 1,getpro) res[aa]&lt;-pro &#125;&#125;#把省份合并到经纬度中jw_data$province&lt;-res[1:length(jw_data$经度1)]#提取非空数据jw_data1&lt;-jw_data[which(jw_data$province!=&quot;&quot;),]###########第二步：查看省份分布及前五名省份######################查看省份分布province&lt;-data.frame(table(jw_data1$province))#提取排名前五的省份province1&lt;-province[order(-province$Freq),]top5pro&lt;-province1[1:5,]#线line&lt;-data.frame(begin=rep(&quot;北京&quot;,5),end=top5pro$Var1)#############第三步：使用REmapC函数绘制填充图#######################result&lt;-remapC(data = province1,maptype = &apos;china&apos;,color =&apos;red&apos;,markPointData = line[,2])plot(result) 系统规则123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101##########第一部分：每天的结果代码标签，与变量的关系########################vec&lt;-function(x)&#123; #每天随机生成的标签 x&lt;-sample(0:4,size = x,replace = TRUE) label&lt;-unlist(sapply(x,function(x)&#123;x&lt;-switch(x,&quot;label_未跟进&quot;,&quot;label_无效联络&quot;,&quot;label_有效非P&quot;,&quot;PTP&quot;);return(x)&#125;)) label1&lt;-factor(label,levels = c(&quot;label_未跟进&quot;,&quot;label_无效联络&quot;,&quot;label_有效非P&quot;,&quot;PTP&quot;)) label2&lt;-names(summary(label1)[summary(label1)!=0]) label3&lt;-label2[length(label2)] label3 #定义四个标签对应的四个变量 vector_wgj&lt;-0 vector_wxll&lt;-0 vector_yxfp&lt;-0 vector_ptp&lt;-0 #判断一天最后应该的字段 if(&quot;label_未跟进&quot; %in% label3)&#123; vector_wgj&lt;-vector_wgj+1 vector_wxll&lt;-0 vector_yxfp&lt;-0 vector_ptp&lt;-0 &#125; else if(&quot;label_无效联络&quot; %in% label3)&#123; vector_wgj&lt;-0 vector_wxll&lt;-vector_wxll+1 vector_yxfp&lt;-0 vector_ptp&lt;-0 &#125; else if (&quot;label_有效非P&quot; %in% label3)&#123; vector_wgj&lt;-0 vector_wxll&lt;-0 vector_yxfp&lt;-vector_yxfp+1 vector_ptp&lt;-0 &#125; else if(&quot;PTP&quot; %in% label3)&#123; vector_ptp&lt;-vector_ptp+1 vector_wgj&lt;-0 vector_wxll&lt;-0 vector_yxfp&lt;-0 &#125; #print(c(结果代码=label,最高级结果=label3)) return(c(vector_wgj=vector_wgj,vector_wxll=vector_wxll,vector_yxfp=vector_yxfp,vector_ptp=vector_ptp))&#125;##一天留几条结果代码a&lt;-vec(4)a#####这是累积的结果代码产生的结果变量vector_wgj&lt;-0vector_wxll&lt;-0vector_yxfp&lt;-0vector_ptp&lt;-0#30天后，结果代码对变量产生的合计for(i in 1:30)&#123; last&lt;-vec(4) #一天下多少次结果代码 vector_wgj&lt;-vector_wgj+last[&quot;vector_wgj&quot;] vector_wxll&lt;-vector_wxll+last[&quot;vector_wxll&quot;] vector_yxfp&lt;-vector_yxfp+last[&quot;vector_yxfp&quot;] vector_ptp&lt;-vector_ptp+last[&apos;vector_ptp&apos;]&#125;vect&lt;-c(vector_wgj=vector_wgj,vector_wxll=vector_wxll,vector_yxfp=vector_yxfp,vector_ptp=vector_ptp)vect######会归0的结果变量vector_wgj&lt;-0vector_wxll&lt;-0vector_yxfp&lt;-0vector_ptp&lt;-0for(i in 1:30)&#123; last&lt;-vec(4) #一天下多少次结果代码 if(names(last[last==1])==&quot;vector_ptp&quot;)&#123; vector_wgj&lt;-0 vector_wxll&lt;-0 vector_yxfp&lt;-0 &#125; else if(names(last[last==1])==&quot;vector_yxfp&quot;)&#123; vector_wgj&lt;-0 vector_wxll&lt;-0 &#125; else if(names(last[last==1])==&quot;vector_wxll&quot;)&#123; vector_wgj&lt;-0 &#125; vector_wgj&lt;-vector_wgj+last[&quot;vector_wgj&quot;] vector_wxll&lt;-vector_wxll+last[&quot;vector_wxll&quot;] vector_yxfp&lt;-vector_yxfp+last[&quot;vector_yxfp&quot;] vector_ptp&lt;-vector_ptp+last[&apos;vector_ptp&apos;] print(c(vector_wgj=vector_wgj,vector_wxll=vector_wxll,vector_yxfp=vector_yxfp,vector_ptp=vector_ptp)) if(vector_ptp!=0)&#123; vector_wgj&lt;-0 vector_wxll&lt;-0 vector_yxfp&lt;-0 &#125; else if(vector_yxfp!=0)&#123; vector_wgj&lt;-0 vector_wxll&lt;-0 &#125; else if(vector_wxll!=0)&#123; vector_wgj&lt;-0 &#125;&#125;vect&lt;-c(vector_wgj=vector_wgj,vector_wxll=vector_wxll,vector_yxfp=vector_yxfp,vector_ptp=vector_ptp)vect]]></content>
      <categories>
        <category>百度地图</category>
      </categories>
      <tags>
        <tag>R语言</tag>
        <tag>填充图</tag>
        <tag>系统规则</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用百度地图监测外访地点]]></title>
    <url>%2Fxiaoyue.github.io%2F2019%2F08%2F09%2Fwaifang%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232###从github上加载REmap包#install.packages(c(&quot;devtools&quot;,&quot;rlist&quot;,&quot;RCurl&quot;,&quot;geosphere&quot;))library(devtools) library(stringr) library(rlist)install_github(&apos;lchiffon/REmap&apos;) #作者/包名library(REmap)library(RCurl)library(rjson)library(geosphere) #计算经纬度间的距离######读取外访队列数据和发外访的地址数据##########data&lt;-read.csv(file = &quot;E:/jingwei/队列经纬度.csv&quot;,sep=&quot;,&quot;,header = TRUE)address&lt;-read.csv(file = &quot;E:/jingwei/地址.csv&quot;,sep=&quot;,&quot;,header = TRUE)######对外访队列数据进行处理##########对队列进行处理###city&lt;-data$队列city#####提取队列的省市#######按照_划分包含区省市三个元素的列表###a&lt;-str_split(city,pattern = &quot;_&quot;)####分别提取列表的第二个和第三个元素，即省市####prov&lt;-sapply(a,function(x) x[2])town&lt;-sapply(a,function(x) x[3])##去掉队列取市###x&lt;-regexpr(&quot;队&quot;, town)-1y&lt;-rep(1,length(x))town1&lt;-substr(town,y,x)######去重######town2&lt;-unique(town1)town2#############查询外访地址经纬度，最高支持12000个地址进行查找#################################################################正向匹配具体地址的经纬度###############################################jw1&lt;-function(x)&#123; b&lt;-data.frame(城市=c(),经度=c(),纬度=c()) for(i in 1:length(x))&#123; if (i&lt;=3000)&#123; if (x[i]==&quot;&quot;) &#123; b[i,1]&lt;-&quot;&quot; b[i,2]&lt;-&quot;NA&quot; b[i,3]&lt;-&quot;NA&quot; &#125; else &#123; location&lt;-gsub(&apos;[[:punct:]]|￥-&apos;,&apos;&apos;,x[i]) ak&lt;-&quot;o19PIiEcPHfWKstH1jONtO7mw2ntn8cT&quot; url &lt;- paste(&quot;http://api.map.baidu.com/geocoder/v2/?address=&quot;,location,&quot;&amp;output=json&amp;ak=&quot;,ak,sep=&quot;&quot;) url_string &lt;- URLencode(url) json&lt;- readLines(url_string,warn = FALSE) geo&lt;-fromJSON(json) if (geo$status==1) &#123; b[i,1]&lt;-x[i] b[i,2]&lt;-&quot;NA&quot; b[i,3]&lt;-&quot;NA&quot; &#125; else &#123; if (length(geo$results)&gt;0) &#123; url &lt;- paste(&quot;http://api.map.baidu.com/geocoder/v2/?address=&quot;,location,&quot;&amp;output=json&amp;ak=&quot;,ak,sep=&quot;&quot;) url_string &lt;- URLencode(url) json&lt;- readLines(url_string,warn = FALSE) geo&lt;-fromJSON(json) b[i,1]&lt;-x[i] b[i,2]&lt;-geo$result$location$lng b[i,3]&lt;-geo$result$location$lat &#125; else &#123; location&lt;-substr(gsub(&quot; &quot;,&quot;&quot;,location),1,40) url &lt;- paste(&quot;http://api.map.baidu.com/geocoder/v2/?address=&quot;,location,&quot;&amp;output=json&amp;ak=&quot;,ak,sep=&quot;&quot;) url_string &lt;- URLencode(url) json&lt;- readLines(url_string,warn = FALSE) geo&lt;-fromJSON(json) b[i,1]&lt;-x[i] b[i,2]&lt;-geo$result$location$lng b[i,3]&lt;-geo$result$location$lat &#125; &#125; &#125; &#125; else if (i&lt;=6000)&#123; if (x[i]==&quot;&quot;) &#123; b[i,1]&lt;-&quot;&quot; b[i,2]&lt;-&quot;NA&quot; b[i,3]&lt;-&quot;NA&quot; &#125; else &#123; location&lt;-gsub(&apos;[[:punct:]]|￥-&apos;,&apos;&apos;,x[i]) ak&lt;-&quot;dDOKBdXFCG7TnyFvMScTlOmI&quot; url &lt;- paste(&quot;http://api.map.baidu.com/geocoder/v2/?address=&quot;,location,&quot;&amp;output=json&amp;ak=&quot;,ak,sep=&quot;&quot;) url_string &lt;- URLencode(url) json&lt;- readLines(url_string,warn = FALSE) geo&lt;-fromJSON(json) if (geo$status==1) &#123; b[i,1]&lt;-x[i] b[i,2]&lt;-&quot;NA&quot; b[i,3]&lt;-&quot;NA&quot; &#125; else &#123; if (length(geo$results)&gt;0) &#123; url &lt;- paste(&quot;http://api.map.baidu.com/geocoder/v2/?address=&quot;,location,&quot;&amp;output=json&amp;ak=&quot;,ak,sep=&quot;&quot;) url_string &lt;- URLencode(url) json&lt;- readLines(url_string,warn = FALSE) geo&lt;-fromJSON(json) b[i,1]&lt;-x[i] b[i,2]&lt;-geo$result$location$lng b[i,3]&lt;-geo$result$location$lat &#125; else &#123; location&lt;-substr(gsub(&quot; &quot;,&quot;&quot;,location),1,40) url &lt;- paste(&quot;http://api.map.baidu.com/geocoder/v2/?address=&quot;,location,&quot;&amp;output=json&amp;ak=&quot;,ak,sep=&quot;&quot;) url_string &lt;- URLencode(url) json&lt;- readLines(url_string,warn = FALSE) geo&lt;-fromJSON(json) b[i,1]&lt;-x[i] b[i,2]&lt;-geo$result$location$lng b[i,3]&lt;-geo$result$location$lat &#125; &#125; &#125; &#125; else if (i&lt;=9000)&#123; if (x[i]==&quot;&quot;) &#123; b[i,1]&lt;-&quot;&quot; b[i,2]&lt;-&quot;NA&quot; b[i,3]&lt;-&quot;NA&quot; &#125; else &#123; location&lt;-gsub(&apos;[[:punct:]]|￥-&apos;,&apos;&apos;,x[i]) ak&lt;-&quot;134db1b9cf1f1f2b4427210932b34dcb&quot; url &lt;- paste(&quot;http://api.map.baidu.com/geocoder/v2/?address=&quot;,location,&quot;&amp;output=json&amp;ak=&quot;,ak,sep=&quot;&quot;) url_string &lt;- URLencode(url) json&lt;- readLines(url_string,warn = FALSE) geo&lt;-fromJSON(json) if (geo$status==1) &#123; b[i,1]&lt;-x[i] b[i,2]&lt;-&quot;NA&quot; b[i,3]&lt;-&quot;NA&quot; &#125; else &#123; if (length(geo$results)&gt;0) &#123; url &lt;- paste(&quot;http://api.map.baidu.com/geocoder/v2/?address=&quot;,location,&quot;&amp;output=json&amp;ak=&quot;,ak,sep=&quot;&quot;) url_string &lt;- URLencode(url) json&lt;- readLines(url_string,warn = FALSE) geo&lt;-fromJSON(json) b[i,1]&lt;-x[i] b[i,2]&lt;-geo$result$location$lng b[i,3]&lt;-geo$result$location$lat &#125; else &#123; location&lt;-substr(gsub(&quot; &quot;,&quot;&quot;,location),1,40) url &lt;- paste(&quot;http://api.map.baidu.com/geocoder/v2/?address=&quot;,location,&quot;&amp;output=json&amp;ak=&quot;,ak,sep=&quot;&quot;) url_string &lt;- URLencode(url) json&lt;- readLines(url_string,warn = FALSE) geo&lt;-fromJSON(json) b[i,1]&lt;-x[i] b[i,2]&lt;-geo$result$location$lng b[i,3]&lt;-geo$result$location$lat &#125; &#125; &#125; &#125; else &#123; if (x[i]==&quot;&quot;) &#123; b[i,1]&lt;-&quot;&quot; b[i,2]&lt;-&quot;NA&quot; b[i,3]&lt;-&quot;NA&quot; &#125; else &#123; location&lt;-gsub(&apos;[[:punct:]]|￥-&apos;,&apos;&apos;,x[i]) ak&lt;-&quot;5Rws6aTv40TmiIupfX93COOfyajQ5ZZp&quot; url &lt;- paste(&quot;http://api.map.baidu.com/geocoder/v2/?address=&quot;,location,&quot;&amp;output=json&amp;ak=&quot;,ak,sep=&quot;&quot;) url_string &lt;- URLencode(url) json&lt;- readLines(url_string,warn = FALSE) geo&lt;-fromJSON(json) if (geo$status==1) &#123; b[i,1]&lt;-x[i] b[i,2]&lt;-&quot;NA&quot; b[i,3]&lt;-&quot;NA&quot; &#125; else &#123; if (length(geo$results)&gt;0) &#123; url &lt;- paste(&quot;http://api.map.baidu.com/geocoder/v2/?address=&quot;,location,&quot;&amp;output=json&amp;ak=&quot;,ak,sep=&quot;&quot;) url_string &lt;- URLencode(url) json&lt;- readLines(url_string,warn = FALSE) geo&lt;-fromJSON(json) b[i,1]&lt;-x[i] b[i,2]&lt;-geo$result$location$lng b[i,3]&lt;-geo$result$location$lat &#125; else &#123; location&lt;-substr(gsub(&quot; &quot;,&quot;&quot;,location),1,40) url &lt;- paste(&quot;http://api.map.baidu.com/geocoder/v2/?address=&quot;,location,&quot;&amp;output=json&amp;ak=&quot;,ak,sep=&quot;&quot;) url_string &lt;- URLencode(url) json&lt;- readLines(url_string,warn = FALSE) geo&lt;-fromJSON(json) b[i,1]&lt;-x[i] b[i,2]&lt;-geo$result$location$lng b[i,3]&lt;-geo$result$location$lat &#125; &#125; &#125; &#125; &#125; names(b)&lt;-c(&apos;城市1&apos;,&apos;经度&apos;,&apos;纬度&apos;) return(b)&#125;###########匹配城市的经纬度#############data$城市&lt;-substr(sapply(str_split(data$队列,pattern = &quot;_&quot;),function(x) x[3]),1,regexpr(&quot;队&quot;,sapply(str_split(data$队列,pattern = &quot;_&quot;),function(x) x[3]))-1)a&lt;-jw1(town2)data1&lt;-merge(data,a,by.x=&quot;城市&quot;,by.y = &quot;城市1&quot;)####导出为csv###setwd(&quot;E:/jingwei&quot;)write.table(data1,file=&quot;队列经纬度.csv&quot;,sep=&quot;,&quot;)#############匹配具体地址的经纬度###################address[,c(4,5,6)]&lt;-jw1(address$OUT_ADDRESS_DETAIL)setwd(&quot;E:/jingwei&quot;)write.csv(x = address,file=&quot;外访匹配后地址.csv&quot;)##################开始计算经纬度的距离########################查看包内都有哪些函数##help(package=&quot;geosphere&quot;)##读入数据new_data&lt;-read.csv(file = &quot;E:/jingwei/队列经纬度.csv&quot;,sep = &quot;,&quot;)##使用distm函数进行距离计算for (i in 1:length(new_data$经度1))&#123; a&lt;-as.vector(new_data[i,19:20]) names(a)&lt;-c(1,2) b&lt;-as.vector(new_data[i,22:23]) names(b)&lt;-c(1,2) new_data$距离[i]&lt;-(distm(rbind(a,b))[1,2])/1000&#125;setwd(&quot;E:/jingwei&quot;)write.csv(x = new_data,file=&quot;juli.csv&quot;)]]></content>
      <categories>
        <category>百度地图秘钥</category>
      </categories>
      <tags>
        <tag>R语言</tag>
        <tag>百度地图</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日常数据提取及批量查看数据预测能力]]></title>
    <url>%2Fxiaoyue.github.io%2F2019%2F08%2F09%2Fdaima%2F</url>
    <content type="text"><![CDATA[数据提取123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186library(RODBC)library(tidyverse)library(openxlsx)#开始日期start_date&lt;-&apos;2019-06-01&apos;#与mysql建立连接通道channel&lt;-odbcConnect(&apos;mysql_data&apos;,uid = &apos;***&apos;,pwd = &apos;***&apos;)#查看库中(即通道)所有表#sqlTables(channel)######################################################################################################part1:贷后数据######################################################################################################################读取库中(即通道)中的贷后表现表。类似于复制粘贴#data&lt;-sqlFetch(channel,sqtable = &apos;cl_repay_recall_loan_detail&apos;)#对库中的贷后表现表，进行查询.options(stringsAsFactors = F)str&lt;-paste(&quot;select t1.* ,case when t1.extension_type is null or t1.extension_type =&apos;&apos; then t1.repay_state when t1.extension_type = &apos;逾前展期&apos; then &apos;正常还款&apos; when t1.extension_type = &apos;逾后展期&apos; then &apos;逾期结清&apos; when t1.extension_type = &apos;逾前延期&apos; and t1.repay_state = &apos;逾期未还&apos; then &apos;逾期未还&apos; when t1.extension_type = &apos;逾前延期&apos; and t1.repay_state = &apos;逾期结清&apos; then &apos;逾期结清&apos; when t1.extension_type = &apos;逾前延期&apos; then &apos;正常还款&apos; when t1.extension_type = &apos;逾后延期&apos; and t1.repay_state = &apos;逾期未还&apos; then &apos;逾期未还&apos; when t1.extension_type = &apos;逾后延期&apos; and t1.repay_state = &apos;逾期结清&apos; then &apos;逾期结清&apos; when t1.extension_type = &apos;逾后延期&apos; then &apos;正常还款&apos; else &apos;&apos; end as repay_state_tjfrom ( select riskcontrol_match_id ,order_no ,fy_system_sn ,user_id ,user_name ,user_id_card ,phone_nm ,device_type ,product_code ,case when user_type = &apos;new&apos; then &apos;首借&apos; when user_type = &apos;old&apos; then &apos;复借&apos; else &apos;&apos; end as user_type ,channel_code ,channel_name ,strategybranch_id ,strategybranch_name ,from_unixtime(borrow_time,&apos;%Y-%m-%d&apos;) as borrow_time ,from_unixtime(real_recive_time,&apos;%Y-%m-%d&apos;) as real_recive_time ,from_unixtime(original_real_recive_time,&apos;%Y-%m-%d&apos;) as original_real_recive_time ,from_unixtime(plan_repay_time,&apos;%Y-%m-%d&apos;) as plan_repay_time ,from_unixtime(real_repay_time,&apos;%Y-%m-%d&apos;) as real_repay_time ,penalty_day ,from_unixtime(extension_begin_time,&apos;%Y-%m-%d&apos;) as extension_begin_time ,extension_cnt ,case when extension_type = &apos;1&apos; then &apos;逾前展期&apos; when extension_type = &apos;2&apos; then &apos;逾前延期&apos; when extension_type = &apos;3&apos; then &apos;逾后展期&apos; when extension_type = &apos;4&apos; then &apos;逾后延期&apos; else &apos;&apos; end as extension_type ,from_unixtime(extension_plan_repay_time,&apos;%Y-%m-%d&apos;) as extension_plan_repay_time ,from_unixtime(extension_real_repay_time,&apos;%Y-%m-%d&apos;) as extension_real_repay_time ,extension_penalty_day ,repay_phase_num ,phase_num ,borrow_term_unit ,borrow_term ,borrow_amount ,real_recive_amount ,case when repay_state = &apos;30&apos; then &apos;未到期&apos; when repay_state = &apos;35&apos; then &apos;已展期&apos; when repay_state = &apos;39&apos; then &apos;提前还款&apos; when repay_state = &apos;40&apos; then &apos;正常还款&apos; when repay_state = &apos;45&apos; then &apos;逾期结清&apos; when repay_state = &apos;50&apos; then &apos;逾期未还&apos; else &apos;&apos; end as repay_state ,case when extension_repay_state = &apos;30&apos; then &apos;展期未到期&apos; when extension_repay_state = &apos;35&apos; then &apos;二次展期&apos; when extension_repay_state = &apos;39&apos; then &apos;展期提前还款&apos; when extension_repay_state = &apos;40&apos; then &apos;展期正常还款&apos; when extension_repay_state = &apos;45&apos; then &apos;展期逾期结清&apos; when extension_repay_state = &apos;50&apos; then &apos;展期逾期未还&apos; else &apos;&apos; end as extension_repay_state ,repay_amount ,fy_merchant_id ,fy_merchant_namefrom cl_repay_recall_loan_detail where order_no is not null and order_no != &apos;&apos; ) t1 where t1.original_real_recive_time &gt;= &quot;,&quot;&apos;&quot;,start_date,&quot;&apos;&quot;,sep=&apos;&apos;)#贷后数据查询data&lt;-sqlQuery(channel,str)#按照商户名称、原始逾期状态进行计数show_data&lt;-data%&gt;%filter(as.Date(original_real_recive_time,&apos;%Y-%m-%d&apos;)&lt;Sys.Date())%&gt;% select(original_real_recive_time,repay_state_tj,fy_merchant_name,fy_system_sn)%&gt;% group_by(fy_merchant_name,repay_state_tj)%&gt;%count(repay_state_tj)#对商户名称中NA缺失数据，更改为字符型NAshow_data$fy_merchant_name[which(is.na(show_data$fy_merchant_name),)]&lt;-&apos;NA&apos;#对原始逾期状态为空的缺失数据，更改为字符空白show_data$repay_state_tj[which(show_data$repay_state_tj==&quot;&quot;,)]&lt;-&apos;空白&apos;#对show_data行列转换show_data_trans&lt;-tapply(show_data$n,list(show_data$fy_merchant_name,show_data$repay_state_tj),sum)show_data_trans#贷后数据导出#创建列表，包含导出的两个sheet表v&lt;-list(&apos;贷后数据源&apos;=data,&apos;贷后展示&apos;=as.data.frame(show_data_trans))#数据导出nn&lt;-paste(&apos;D:/数据质量/R输出结果/贷后数据&apos;,Sys.Date(),&apos;.xlsx&apos;,sep = &apos;&apos;)write.xlsx(v,file = nn,asTable = c(T,T),withFilter=c(T,T),colwiths=c(&apos;auto&apos;,&apos;auto&apos;),row.names=T)######################################################################################################part2:贷前数据######################################################################################################################贷前查询代码str2&lt;-paste(&quot;select fy_system_sn ,user_id ,user_name ,user_id_card ,phone_nm ,device_type ,product_code ,case when user_type = &apos;new&apos; then &apos;首借&apos; when user_type = &apos;old&apos; then &apos;复借&apos; else &apos;未判定&apos; end as user_type ,channel_code ,channel_name ,strategybranch_id ,strategybranch_name ,from_unixtime(borrow_time,&apos;%Y-%m-%d&apos;) as borrow_time ,from_unixtime(risk_begin_time,&apos;%Y-%m-%d&apos;) as risk_begin_time ,from_unixtime(real_recive_time,&apos;%Y-%m-%d&apos;) as real_recive_time ,borrow_amount ,real_recive_amount ,case when risk_audit_result = &apos;ACCEPT&apos; then &apos;通过&apos; when risk_audit_result = &apos;REJECT&apos; then &apos;拒绝&apos; when risk_audit_result = &apos;REVIEW&apos; then &apos;复审&apos; else &apos;&apos; end as risk_audit_result ,case when manual_audit_result = &apos;0&apos; then &apos;未认证&apos; when manual_audit_result = &apos;10&apos; then &apos;申请&apos; when manual_audit_result = &apos;20&apos; then &apos;通过&apos; when manual_audit_result = &apos;30&apos; then &apos;驳回&apos; when manual_audit_result = &apos;40&apos; then &apos;拒绝&apos; else &apos;&apos; end as manual_audit_result ,case when risk_audit_result = &apos;REJECT&apos; or manual_audit_result = &apos;40&apos; then &apos;拒绝&apos; when risk_audit_result = &apos;ACCEPT&apos; or manual_audit_result = &apos;20&apos; then &apos;通过&apos; when risk_audit_result = &apos;REVIEW&apos; and manual_audit_result = &apos;0&apos; then &apos;人工未认证&apos; when risk_audit_result = &apos;REVIEW&apos; and manual_audit_result = &apos;10&apos; then &apos;申请&apos; when risk_audit_result = &apos;REVIEW&apos; and manual_audit_result = &apos;30&apos; then &apos;驳回&apos; else &apos;&apos; end as final_audit_result ,fy_merchant_id ,fy_merchant_name from cl_property_apply_info where borrow_time &gt;= &quot;,&quot;&apos;&quot;,start_date,&quot;&apos;&quot;,sep=&apos;&apos;)#与mysql建立连接通道channel&lt;-odbcConnect(&apos;mysql_data&apos;,uid = &apos;zhaolei&apos;,pwd = &apos;fm123456&apos;)#贷前数据查询dq_data&lt;-sqlQuery(channel,str2)#按照商户名称、机审结果进行计数dq_show_data&lt;-dq_data%&gt;%select(fy_merchant_name,risk_audit_result,fy_system_sn)%&gt;% group_by(fy_merchant_name,risk_audit_result)%&gt;%count(risk_audit_result)#对商户名称中NA和缺失数据，更改为字符型NAdq_show_data$fy_merchant_name[which(is.na(dq_show_data$fy_merchant_name),)]&lt;-&apos;NA&apos;dq_show_data$fy_merchant_name[which(dq_show_data$fy_merchant_name==&apos;&apos;,)]&lt;-&apos;NA&apos;#对原始逾期状态为空的缺失数据，更改为字符空白dq_show_data$risk_audit_result[which(is.na(dq_show_data$risk_audit_result),)]&lt;-&apos;空白&apos;dq_show_data$risk_audit_result[which(dq_show_data$risk_audit_result==&apos;&apos;,)]&lt;-&apos;空白&apos;#对dq_show_data行列转换dq_show_data_trans&lt;-tapply(dq_show_data$n,list(dq_show_data$fy_merchant_name,dq_show_data$risk_audit_result),sum)#贷前数据导出#创建列表，包含导出的两个sheet表l&lt;-list(&apos;贷前数据源&apos;=dq_data,&apos;贷前展示&apos;=as.data.frame(dq_show_data_trans))#数据导出nn1&lt;-paste(&apos;D:/数据质量/R输出结果/贷前数据&apos;,Sys.Date(),&apos;.xlsx&apos;,sep = &apos;&apos;)write.xlsx(l,file = nn1,asTable = c(T,T),withFilter=c(T,T),colwiths=c(&apos;auto&apos;,&apos;auto&apos;),row.names=T) 查看外部数据测试预测能力123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170library(openxlsx)library(smbinning)library(stringr)library(gbm)library(tidyverse)library(import)library(reshape)import::from(&quot;D:/R/mob.R&quot;, manual_bin)#####导入数据###data&lt;-read.xlsx(&apos;D:/表1.xlsx&apos;,sheet = &apos;Sheet1&apos;)str(data)summary(data)#####声明分类变量cla.var&lt;-c(&apos;渠道&apos;,&apos;当前逾期情况&apos;)#####修改部分变量为字符型data&lt;-mutate_at(data,cla.var,as.character)str(data)#####修改状态###for(i in 1:nrow(data))&#123; if(data$好坏标识[i]==1)&#123; data$new_label[i]&lt;-0 &#125; else data$new_label[i]&lt;-1&#125;######提取数据商户和策略unique(data$规则集名称)data1&lt;-data[which(data$商户==&apos;****&apos;&amp;data$规则集名称==&apos;****&apos;),]######提取数值型数据####dt&lt;-select_if(data1,is.numeric)dt1&lt;-select(dt,-id,-好坏标识)dt&lt;-dt1#####定义计算分箱公式###iso_bin &lt;- function(data, y, x) &#123; # INPUT # data: input dataframe # y : name of Y in the input dataframe with binary 0/1 values # x : name of X in the input dataframe with numeric values yname &lt;- y xname &lt;- x df1 &lt;- subset(data, !is.na(data[[xname]]) &amp; data[[yname]] %in% c(0, 1), select = c(xname, yname)) df2 &lt;- df1[order(df1[[xname]]), ] spcor &lt;- cor(df2[, 2], df2[, 1], method = &quot;spearman&quot;, use = &quot;complete.obs&quot;) df3 &lt;- with(isoreg(df2[[xname]], spcor / abs(spcor) * df2[[yname]]), data.frame(x = x, y = y, yhat = yf)) df4 &lt;- Reduce(rbind, lapply(split(df3, df3$yhat), function(x) data.frame(maxx = max(x$x), yavg = abs(mean(x$y)), yhat = abs(round(mean(x$yhat), 8))))) df5 &lt;- df4[order(df4$maxx), ] h &lt;- ifelse(df5[[&quot;yavg&quot;]][1] %in% c(0, 1), 2, 1) t &lt;- ifelse(df5[[&quot;yavg&quot;]][nrow(df5)] %in% c(0, 1), 2, 1) cuts &lt;- df5$maxx[h:(nrow(df5) - t)] return(list(df = manual_bin(data, yname, xname, cuts = cuts), cuts = cuts))&#125;#自定义Ks函数及AUC值函数.输入x为smbinning$ivtable的数据框getks&lt;-function(x)&#123; for(i in 1:nrow(x))&#123; x$CumgoodRate[i]&lt;-x$CntCumGood[i]/x$CntGood[nrow(x)] x$CumbadRate[i]&lt;-x$CntCumBad[i]/x$CntBad[nrow(x)] x$Ks[i]&lt;-abs(x$CumgoodRate[i]-x$CumbadRate[i]) x$Ks[nrow(x)]&lt;-max(x$Ks,na.rm = T) if(i==1)&#123; x$lag_CumgoodRate[i]&lt;-0 x$lag_CumbadRate[i]&lt;-0 &#125; else &#123; x$lag_CumgoodRate[i]&lt;-x$CumgoodRate[i-1] x$lag_CumbadRate[i]&lt;-x$CumbadRate[i-1] &#125; x$AUC[i]&lt;-((x$CumbadRate[i]+x$lag_CumbadRate[i])*(x$CumgoodRate[i]-x$lag_CumgoodRate[i]))/2 x$AUC[nrow(x)]&lt;-sum(x$AUC,na.rm = T) &#125; #list(table = x, iv = x$IV[nrow(x)], ks = x$Ks[nrow(x)], AUC = x$AUC[nrow(x)]) data.frame(iv = x$IV[nrow(x)], ks = x$Ks[nrow(x)], AUC = x$AUC[nrow(x)])&#125;#创建空数据框result_last&lt;-data.frame(变量=c(),iv=c(),Ks=c(),AUC=c())#创建空向量,方便后续装填变量vec&lt;-c()######循环取分箱值for(i in 1:213)&#123; print(i) x.inv&lt;-try( &#123; bin&lt;-iso_bin(dt,&apos;new_label&apos;,names(dt)[i]) bins&lt;-as.vector(bin$cuts) result&lt;-smbinning.custom(dt,y=&apos;new_label&apos;,x=names(dt)[i],cuts = bins) if(result==&apos;Uniques values &lt; 5&apos;) &#123; print(&apos;Uniques values &lt; 5&apos;) vec&lt;-c(vec,names(dt)[i]) next&#125; result_data&lt;-as.data.frame(result$ivtable) getks(result_data) a&lt;-data.frame(变量=names(dt)[i],getks(result_data)) result_last&lt;-rbind(result_last,a) &#125;,silent = T) if(&apos;try-error&apos; %in% class(x.inv)) &#123; print(x.inv) next&#125;&#125;###############处理分类变量#######分类变量揉进vec向量vec&lt;-c(vec,cla.var)vecfor(i in 1:length(vec))&#123; dtt&lt;-dt%&gt;%group_by(eval(parse(text=data1[vec[i]])),eval(parse(text=&apos;new_label&apos;)))%&gt;%count names(dtt)&lt;-c(&apos;x&apos;,&apos;y&apos;,&apos;n&apos;) aa&lt;-as.data.frame(cast(dtt,x~y,value=&apos;n&apos;)) badcum&lt;-as.vector(apply(aa[,2:3],2,function(x) sum(x,na.rm = T))[1]) goodcum&lt;-as.vector(apply(aa[,2:3],2,function(x) sum(x,na.rm = T))[2]) badper&lt;-aa[,&apos;0&apos;]/badcum goodper&lt;-aa[,&apos;1&apos;]/goodcum woe1&lt;-log((badper/goodper)) iv&lt;-(badper-goodper)*woe1 cum.iv&lt;-sum(iv,na.rm = T) aa[is.na(aa[,&apos;0&apos;]),&apos;0&apos;]&lt;-0 aa[is.na(aa[,&apos;1&apos;]),&apos;1&apos;]&lt;-0 CntCumBad&lt;-cumsum(aa[,&apos;0&apos;]) CntCumGood&lt;-cumsum(aa[,&apos;1&apos;]) CntCumBadper&lt;-cumsum(aa[,&apos;0&apos;])/badcum CntCumGoodper&lt;-cumsum(aa[,&apos;1&apos;])/goodcum ks&lt;-abs(CntCumBadper-CntCumGoodper) max.ks&lt;-max(ks,na.rm = T) aa.t&lt;-cbind(aa,badper,goodper,woe1,iv,CntCumBad,CntCumGood,CntCumBadper,CntCumGoodper,ks) getks_class&lt;-function(x)&#123; for(i in 1:nrow(x))&#123; if(i==1)&#123; x$lag_CumgoodRate[i]&lt;-0 x$lag_CumbadRate[i]&lt;-0 &#125; else &#123; x$lag_CumgoodRate[i]&lt;-x$CntCumGoodper[i-1] x$lag_CumbadRate[i]&lt;-x$CntCumBadper[i-1] &#125; x$AUC[i]&lt;-((x$CntCumBadper[i]+x$lag_CumbadRate[i])*(x$CntCumGoodper[i]-x$lag_CumgoodRate[i]))/2 &#125; data.frame(iv = sum(x$iv,na.rm = T), ks = max(x$ks,na.rm = T), AUC = sum(x$AUC,na.rm = T)) &#125; a&lt;-data.frame(变量=vec[i],getks_class(aa.t)) result_last&lt;-rbind(result_last,a)&#125;write.xlsx(result_last,&apos;D:/导出.xlsx&apos;)]]></content>
  </entry>
  <entry>
    <title><![CDATA[基于逻辑回归评分卡模型开发及实现.html]]></title>
    <url>%2Fxiaoyue.github.io%2F2019%2F08%2F08%2Fping%2F</url>
    <content type="text"><![CDATA[1 信用风险评级模型的类型1.1 信用风险计量体系的主体评级模型分类信用风险计量体系的主体评级模型可用四张卡来表示，分别为A卡、B卡、C卡和F卡。 A卡，又称申请评分卡(Applicationscore)，对新贷款申请进行筛选并判断其违约风险；严格来讲，预测该申请客户在未来一段时间发生违约的概率； B卡，又称行为评分卡(Behaviouralscore)，通常是客户贷中进行观测使用，在信用卡方向实践可以是调整额度、预警等等； C卡，又称催收评分卡(Collectionsscore)，通常是预测客户是否违约、或客户违约后还款的可能性； F卡，又称欺诈评分模型，对新贷款申请或交易为欺诈行为的概率进行预测； 1.2 行为评分卡和申请评分卡的区别 通常行为评分卡要比申请评分卡更为精确。因为行为评分卡在对账户状态进行预测时基于更多的数据要素(交易产生的)。 拒绝演绎技术，只在申请评分卡的开发过程中使用。 2 评分卡开发流程2.1 评分卡开发流程图1概括了典型的评分卡开发流程。该流程各个步骤的顺序可以根据具体情况的不同进行调整，也可以根据需要重复某些步骤。^1^ 图1：典型评分卡开发流程 对开发流程具体描述如下： 数据获取：在明确问题(如确定违约或正常的定义和评分卡的范围、开发和实施窗口等)的基础上，从数据渠道角度，获取企业内部或外部数据，其中，内部数据如用户的年龄，户籍，性别，收入，负债比，在本机构的借款和还款行为等,外部数据如征信数据和外部评分等第三方数据；从数据内容角度，获取如设备使用行为、社交网络行为、多头借贷行为和网贷交易行为等。 EDA与数据描述:主要是获取样本总体的大概情况，以便制定样本总体的数据预处理方法。描述样本总体情况的指标主要有缺失值情况、异常值情况、平均值、中位数、最大值、最小值、分布情况等。 数据预处理:主要工作包括数据清洗、缺失值处理、异常值处理、标签定义及特征衍生，主要是为了将获取的原始数据转化为可用作模型开发的格式化数据。 变量选择:主要是通过统计学的方法，筛选出对违约状态影响最显著的指标。 模型开发:主要包括变量分段、变量的WOE（证据权重）变换和逻辑回归估算三部分。 模型评估:主要是根据模型验证和主标尺设计的结果，评估模型的区分能力、预测能力、稳定性，并形成模型评估报告，得出模型是否可以使用的结论。 主标尺与模型验证:主要是开发某类主体的主标尺并进行模型的验证与校准。 模型实施:即模型的部署和应用。 监测与报告:主要工作是定期检测模型的使用情况，并关注和定期检验模型的区分能力与预测能力的变化及模型稳定性的变化，在出现模型可能不能满足业务需求的情况时，反馈至模型开发团队，及时进行模型更新或重新开发。 拒绝演绎:申请评分卡的模型开发过程中使用的数据实际上并不是从申请总体样本中随机选择的，而仅仅是从过去已经被接受的客户样本中选择的。因此，开发申请评分卡时将对被拒绝客户的状态进行推断并纳入模型开发数据集中，即拒绝推断过程。 2.2 信贷业务流程 图2：信贷业务流程 3 数据获取3.1 明确问题3.1.1 明确违约与正常定义 预测模型的基本原理是历史数据预测未来，申请评分卡的目的是预测申请人在未来一段时间发生违约的概率。 观察期是指在设定的观察日之前的一段时间(又称回溯)，表现期是指观察日之后的一段时间。对于评分卡而言，用观察期内申请人的信用历史及表现(X)，以及表现期内申请人的还款表现(Y)，通过模型拟合出X与Y之间的关系。注意，观察日是时间段，非时间点。 图3:观察期表现期 违约定义： (1)、根据业务经验定义： 如对不同账期进行预测，那么不同账期下的违约定义也就不同。 (2)、根据逾期率定义： MOB 0 1 2 3 4 5 6 7 8 9 all_count bad_count 逾期率 0 218269 78639 3232 0 0 0 0 0 2 2 300144 81875 0.27278571 59218 169811 20351 9020 0 16 8 8 2 6 258440 29411 0.11380202 556 4061 3775 17287 7 0 0 0 0 0 25686 17294 0.67328513 184 1233 586 1686 22226 446 0 0 0 2 26363 22674 0.86006904 1 20 5 0 233 13634 2803 8 0 0 16704 16445 0.98449475 0 2 2 0 0 211 14936 911 0 0 16062 15847 0.98661446 0 0 0 2 0 0 179 17223 9 8 17421 17240 0.98961027 0 8 0 0 8 0 8 1292 14262 4 15582 14266 0.91554368 2 2 0 0 0 0 2 4 98 12527 12635 12527 0.99145239 0 10 2 4 0 4 8 12 22 247 309 0 0.0000000 : 表1：MOB逾期率 根据表1和图4的MOB逾期率看，在M4账期逾期率达到98%，逾期率进入一个稳定期。故可将M4+记为违约。 3.1.2 表现期确定 进件月份 进件总数 1 2 3 4 5 6 7 8 9 10 11 12 201901 297 0 0 0 0.33 0.65 1.35 2.22 2.93 3.60 4.15 4.05 4.1 201902 282 0 0 0 0.20 0.69 1.54 1.98 2.58 3.18 4.16 4.15 4.3 201903 564 0 0 0 0.40 1.01 1.97 2.39 3.00 3.67 4.14 4.23 NA 201904 633 0 0 0 0.23 1.20 1.93 2.96 3.12 3.50 4.15 NA NA 201905 606 0 0 0 0.26 0.98 1.79 2.23 3.13 3.60 NA NA NA 201906 852 0 0 0 0.33 1.23 1.55 2.34 3.50 NA NA NA NA 201907 960 0 0 0 0.36 0.92 1.60 2.60 NA NA NA NA NA 201908 731 0 0 0 0.23 1.01 1.70 NA NA NA NA NA NA 201909 740 0 0 0 0.26 1.20 NA NA NA NA NA NA NA 201910 744 0 0 0 0.33 NA NA NA NA NA NA NA NA 201911 713 0 0 0 NA NA NA NA NA NA NA NA NA 201912 662 0 0 NA NA NA NA NA NA NA NA NA NA 总和坏件率 NA 0 0 0 0.35 0.89 1.50 2.20 3.10 3.50 4.15 4.18 4.2 : 表2：进件坏账率 表2最后一列4.3%表示，2019年2月开立的所有账户中，12个月后出现逾期120天以上的账户占样本的比重为4.3%.通过这样统计方法，并绘制样本总体的违约状态变化曲线，即可得到如图5所示的曲线。从图35所示的曲线中我们可以看出，在账户开立第10个月到第12个月时，客户的违约状态达到稳定状态，曲线变得非常平稳。此时，我们可以确定评分卡的表现时间窗口为10个月到12个月.所以，预测开户10-12个月后逾期M4+的概率。 3.2 数据获取一般地，观察期是预测期的3-5倍。以观察日为终点，向前回溯3年历史数据，作为原始数据，建立模型。 4 EDA与数据描述以互联网上经常被用来研究信用风险评级模型的加州大学机器学习数据库中的germancredit data为例，German credit data 的数据来自”klaR”包。 1234567891011121314151617#下载klaR包#install.packages(&apos;klaR&apos;)#加载klaR包library(klaR)## Loading required package: MASS## ## Attaching package: &apos;MASS&apos;## The following object is masked from &apos;package:dplyr&apos;:## ## select#获取GermanCredit数据集data(GermanCredit)#查看数据集View(GermanCredit) 4.1 缺失值处理4.1.1 缺失值识别与可视化 is.na()函数 complete.cases()函数 mice::md.pattern()函数 VIM::aggr()函数 VIM::matrixplot()函数 VIM::marginplot()函数 4.1.2 缺失值处理 直接删除含缺失值的样本数据 根据样本间的相似性填补缺失值 根据变量间的相关关系填补缺失值 4.2 异常值处理4.2.1 异常值检测 单变量离群值检测 多变量离群值检测 局部离群值因子检测 基于聚类方法的离群值检测 4.2.2 异常值处理 直接删除含有异常值的样本 异常值视为缺失值，交给缺失值处理方法处理 用平均值修正 不处理 由于GermanCredit数据属于已处理完毕的数据，所以，跳过缺失和异常值 4.3 查看分布情况 总体分布 1summary(GermanCredit) 单变量分布 12345#查看变量duration分布情况ggplot(data=GermanCredit,mapping = aes(x=duration,y=..count..))+ geom_histogram(fill=&apos;blue&apos;,color=&apos;grey60&apos;,size=0.2,alpha=0.2,binwidth = 5)+ ggtitle(&apos;duration分布情况&apos;)+ theme(plot.title = element_text(hjust = 0.5)) 从上面的频率分布直方图中， 可以看出German CreditData中的贷款期限，大都在40个月以内。而申请人数最多的期限，则是6-10个月的短期贷款。 12345#查看变量amount分布情况ggplot(data=GermanCredit,mapping = aes(x=amount,y=..count..))+ geom_histogram(fill=&apos;blue&apos;,color=&apos;grey60&apos;,size=0.2,alpha=0.2,binwidth = 1000)+ ggtitle(&apos;amount分布情况&apos;)+ theme(plot.title = element_text(hjust = 0.5)) 就贷款金额而言，大多数申请人将其控制在5000马克之内。其中以申请1000-3000马克的小额贷款最多。 12345#查看变量credit_risk分布情况ggplot(data=GermanCredit,mapping = aes(x=credit_risk,y=..count..))+ geom_histogram(fill=&apos;blue&apos;,color=&apos;grey60&apos;,alpha=0.2,stat=&apos;count&apos;)+ ggtitle(&apos;credit_risk分布情况&apos;)+ theme(plot.title = element_text(hjust = 0.5)) ## Warning: Ignoring unknown parameters: binwidth, bins, pad 从图中可以看出，数据集中30%的申请人被划分为违约的坏用户。而剩下70%的人则是好用户。 5 变量选择 ^2^变量选择的目的在收集的所有指标中筛选出对违约状态影响最大的指标。 5.1 变量选择 不使用预测模型 有监督 信息值、卡方统计量、基尼系数 无监督 相关性、聚类分析、主成分分析 使用预测模型 有监督 逐步回归（forward, backward, stepwise） 正则化（AIC, BIC, lasso, ridge） 集成模型（RF, xgboost） 交叉验证 1234567#使用scorecard包var_filter函数,默认删除信息值&lt;0.02、缺失率&gt;95%、单类别比例&gt;95%的变量dt_sel&lt;-var_filter(GermanCredit,&apos;credit_risk&apos;)## [INFO] filtering variables ...dim(GermanCredit)## [1] 1000 21dim(dt_sel)## [1] 1000 15 此处在模型外使用基于IV值的var_filter函数，变量由原来的21个变为15个。 5.2 建模样本切分1234567891011##对于失衡数据需要进行处理，使用SMOTE算法，用R对稀有事件进行超级采样.此处利用caret包的createDataPartition(数据分割功能)函数将##数据随机分成相同的两份set.seed(1234)splitindex&lt;-createDataPartition(dt_sel$credit_risk,p=0.7,list = F) #结果返回行号#data为响应向量，p代表生成训练集的比例，list等于FALSE是不以列表进行输出train&lt;-dt_sel[splitindex,] #生成训练集test&lt;-dt_sel[-splitindex,] #生成测试集dim(train)## [1] 700 15dim(test)## [1] 300 15 6 模型开发6.1 WOE分箱证据权重(Weight ofEvidence,WOE)转换可以将logistic回归模型转变为标准评分卡格式。该转换过程能够简化模型的应用且增加业务解释性，同时能将特征与标签之间的非线性关系转化为线性的。scorecard::woebin函数提供了tree与chimerge两种分箱方法。 123456#woebin对数据集计算woebins&lt;-woebin(dt_sel,y=&apos;credit_risk&apos;,method = &apos;tree&apos;)## [INFO] creating woe binning ...class(bins)## [1] &quot;list&quot;bins$age 123#绘制年龄分箱信息图woebin_plot(bins$age)## $age 一般地，坏客户率或者WOE值趋势线，最多不超过一个拐点(U型或倒U型)；最好是单调的每个分箱的样本数量占比最好大于5%。 年龄分箱图所示，每个分箱的样本数量均大于5%，而坏客户率呈W型，需要手动调整分箱。 12345678910# 手动年龄分组区间break_adj&lt;-list(age=c(26,35,40))# 手动年龄调整分箱bins_adj&lt;-woebin(dt_sel, y=&quot;credit_risk&quot;, breaks_list=break_adj, print_step=0)## [INFO] creating woe binning ...## Warning in check_breaks_list(breaks_list, xs): There are 13 x variables## that donot specified in breaks_list are using optimal binning.# 重绘年龄分箱信息图woebin_plot(bins_adj$age)## $age 6.2 woe转换woe转换把每个变量取值与对应的woe值进行匹配，生成一张新表。 12345678#训练集woe转换train_woe&lt;-woebin_ply(train,bins_adj)## [INFO] converting into woe values ...#测试集woe转换test_woe&lt;-woebin_ply(test,bins_adj)## [INFO] converting into woe values ...#查看新生成的训练集head(train_woe) 6.3 逻辑回归6.3.1 逻辑回归逻辑回归(logistic regression)在信用评分卡开发中起到核心作用。逻辑回归通过sigmoid函数 $y=1/(1+e^{-z})$ 将线性回归模型 $z=\boldsymbol{w}^T\boldsymbol{x}+b$ 产生的预测值转换为一个接近0或1的拟合值： \begin{eqnarray} h(x)&=&\frac{1}{1+e^{-z}} \\&=&\frac{1}{1+e^{-(\boldsymbol{w}^T\boldsymbol{x}+b)}} \end{eqnarray} 上式的 $h(x)$ 可视为事件发生的概率 $p(y=1|\boldsymbol{x})$ ，变换后得到： \ln\frac{p}{1-p}=z=\boldsymbol{w}^T\boldsymbol{x}+b其中， $p/(1-p)$ 为比率(odds)，即违约概率与正常概率的比值。 $\ln{p/(1-p)}$ 为logit函数，即比率的自然对数。因此，逻辑回归实际上是用比率的自然对数作为因变量的线性回归模型。 6.3.2 逻辑回归代价函数(cost function)通过最大似然估计，得到似然函数: \ell(\boldsymbol{w},b)=\sum_i{[y^{(i)}\ln{h(x)^{(i)}}+(1-y^{(i)})\ln{(1-h(x)^{(i)})}]}最大化上式等价于，最小化代价函数(cost function): \begin{eqnarray} J(\boldsymbol{w},b)&=&-\frac{1}{m}\sum_i{\ell(\boldsymbol{w},b)} \\&=&-\frac{1}{m}\sum_i{[y^{(i)}\ln{h(x)^{(i)}}+(1-y^{(i)})\ln{(1-h(x)^{(i)})}]} \end{eqnarray}其中, $h(x)$ 为拟合值, $y$ 为实际标签, $m$ 为样本数量使用梯度下降(gradient descent), 找到合适的参数 $(\boldsymbol{w}, b)$ , 使得 $J(\boldsymbol{w},b)$ 尽可能小: \begin{eqnarray} &&\min{J(\boldsymbol{w},b)}: \\ &&repeat\{ \\ && \boldsymbol{w} := \boldsymbol{w} - \alpha\frac{dJ}{dw} \\ &&\} \end{eqnarray}6.3.3 正则化(regulation)在使得代价函数最小时，尤其当样本特征很多时，容易陷入过拟合问题。为了改善过拟合，通常在代价函数中引入正则化项： \min{J(\boldsymbol{w},b)}+\frac{\lambda}{m}(\alpha||\boldsymbol{w}||_1+\frac{1}{2}(1-\alpha)||\boldsymbol{w}||_2^2)其中，正则化参数 $\lambda&gt;0$ ; $||\boldsymbol{w}||_1=\sum_j{|w_j|}$ 与 $||\boldsymbol{w}||_2^2=\sum_j{w_j^2}=\boldsymbol{w}^T\boldsymbol{w}$ 分别为L1与L2范数正则化，也分别称为LASSO(Least Absolute Shrinkage and Selection Operator)与”岭回归”(ridge regression)。L1与L2范数正则化都有助于降低过拟合风险，但前者更易于获得稀疏解，即求得的 $\boldsymbol{w}$ 会有更少的非零分量。 6.3.4 基于AIC筛选变量step123456789101112131415161718192021222324# 逻辑回归m1&lt;-glm( credit_risk ~ ., family = &quot;binomial&quot;, data = train_woe)# summary(m1)# 基于AIC筛选变量stepm_step&lt;-step(m1, direction=&quot;both&quot;, trace = FALSE)m2&lt;-eval(m_step$call)coefficients&lt;-m2$coefficientscoefficients# (Intercept) status_woe # -0.8893727 0.8699409 # duration_woe credit_history_woe # 0.6539944 0.8902985 # purpose_woe amount_woe # 1.1579628 1.2183788 # savings_woe employment_duration_woe # 0.9256609 0.5346631 # installment_rate_woe personal_status_sex_woe # 2.1857340 0.7922848 # other_debtors_woe age_woe # 2.4504925 0.7679847 # other_installment_plans_woe housing_woe # 0.9097653 0.9852162##检查多重共线性vif(m2) vif取值，(0,10)不存在多重共线性,(10,100)存在多重共线性,(>100)存在严重多重共线性。由此，不存在多重共线性问题。 7 模型评估7.1 训练集评估123456#训练集预测概率train_pred&lt;-predict(m2,,type=&apos;response&apos;,train_woe)## Warning in if (!se.fit) &#123;: 条件的长度大于一，因此只能用其第一元素#模型评估perf_train&lt;-perf_eva( train_pred,train_woe$credit_risk,title=&quot;train&quot;)## [INFO] The threshold of confusion matrix is 0.3026. 123456#查看效果perf_train$pic## TableGrob (1 x 2) &quot;arrange&quot;: 2 grobs## z cells name grob## 1 1 (1-1,1-1) arrange gtable[layout]## 2 2 (1-1,2-2) arrange gtable[layout] 7.2 测试集评估12345#测试集预测概率test_pred&lt;-predict(m2, type=&apos;response&apos;, test_woe)#模型评估perf_test&lt;-perf_eva(test_pred,test_woe$credit_risk,title=&quot;test&quot;)## [INFO] The threshold of confusion matrix is 0.3059. 123456#查看效果perf_test$pic## TableGrob (1 x 2) &quot;arrange&quot;: 2 grobs## z cells name grob## 1 1 (1-1,1-1) arrange gtable[layout]## 2 2 (1-1,2-2) arrange gtable[layout] 测试集的ks在0.43，表明模型对好坏客户的区分能力较强。 8 评分刻度与实施8.1 参数AB计算 对于任意一个用户，违约概率为$p$,则正常概率为$1-p$,则 odds=\frac{p}{1-p} 即$odds$表示一个用户违约概率与正常概率的比率。一般的表现形式如$1:240$,$1:480$等。后面的$odds$比率翻番，其实说的就是此处分母变为$1/2$。 从数量角度解读为241人，1人违约，240人正常,481人，1人违约，480人正常; 从比率角度，即$1:240$等价于0.42%,$1:480$等价于0.21%，数量上分母的翻番，意味着比率上违约概率的降低。 评分卡分值刻度,将分值表示为比率对数的线性表达式： score = A - B\ln(odds)其中，$A$、$B$为常数。式中负号使得违约概率越低，得分越高。 结合上述，得分越高，$odds$分母越大，违约概率越低。从业务角度讲，高分值代表低风险，低分值代表高风险。 逻辑回归模型计算$odds$如下： \ln(odds)=\boldsymbol{w}^T\boldsymbol{x}+b 其中，(\ln(odds)) 为逻辑回归的因变量。 评分卡分值$A$,$B$参数计算 一个评分卡可以设计为评分降低20分，违约比率提高一倍，即分母变为$1/2$。如得分600分的$odds$为$1:240$等价于违约比率0.42%,得分620分的$odds$为$1:480$等价于违约比率0.21% $A$,$B$参数的计算是通过将两个已知或者假设的分值带入$score = A - B\ln(odds)$中得到。通常，需要两个假设： 在某个特定的比率设定特定的预期分值$P_0$ 指定比率翻番的分数$PDO$ 首先，设定$odds$比率$\theta_0$的特定点的分值为$P_0$,然后，$odds$比率为$2\theta_0$的点的分值为$P_0+PDO$,代入$score = A - B\ln(odds)$，可得如下两个公式: P_0=A-Bln(\theta_0)P_0+PDO=A-Bln(2\theta_0)其次，利用消元法解上述两个方程中的常数$A$,$B$，可以看到: B=\frac{PDO}{ln(2)}A=P_0+Bln(\theta_0)最后，假如设定评分卡刻度，使得$odds$比率为$1:60$(违约比正常)时的分值为600分，PDO=20。代入上述两个方程： 12345678910111213alpha_beta&lt;-function(basepoints,baseodds,pdo)&#123; B&lt;-pdo/log(2) A&lt;-basepoints+B*log(baseodds) return(list(A=A,B=B))&#125;x&lt;-alpha_beta(600,1/60,20)x## $A## [1] 481.8622## ## $B## [1] 28.8539 求得$A=481.8622$,$B=28.8539$，代入$score = A - B\ln(odds)$为: score = 481.86-28.85\ln(odds)8.2 分值分配将逻辑回归公式代入评分卡分值公式，可以得到 \begin{eqnarray} score &=& A-B\ln(odds) = A-B(\boldsymbol{w}^T\boldsymbol{x}+b) \\ &=& (A-Bb) - Bw_1x_1 - Bw_2x_2 \cdots - Bw_mx_m \end{eqnarray}其中， $x_1\cdots x_m$ 为最终进入模型的自变量且已经转换为WOE值, $w_i$ 为逻辑回归的变量系数, $b$ 为逻辑回归的截距, $A, B$ 为上页求得的刻度因子。 $Bw_ix_i$ 为变量 $x_i$ 对应的评分， $(A-Bb)$ 为基础分(也可将基础分值平均分配给各个变量)。 123#创建评分卡刻度card&lt;-scorecard(bins_adj,m2)data.table::rbindlist(card,fill = TRUE)[c(1,37:40),1:4] 123456789101112131415161718192021222324252627#评分转换只有一个变量，总分train_score&lt;-scorecard_ply(train,card,only_total_score = TRUE,print_step = 0)test_score&lt;-scorecard_ply(test,card,only_total_score = TRUE,print_step = 0)str(test_score)## Classes &apos;data.table&apos; and &apos;data.frame&apos;: 300 obs. of 1 variable:## $ score: num 319 438 692 399 305 665 585 485 381 476 ...## - attr(*, &quot;.internal.selfref&quot;)=&lt;externalptr&gt;#评分转换包括总分和各变量的分值train_score1&lt;-scorecard_ply(train,card,only_total_score = FALSE,print_step = 0)test_score1&lt;-scorecard_ply(test,card,only_total_score = FALSE,print_step = 0)str(test_score1)## Classes &apos;data.table&apos; and &apos;data.frame&apos;: 300 obs. of 14 variables:## $ status_points : num -39 -39 74 -39 -39 74 -39 -39 -39 -39 ...## $ duration_points : num -5 -25 16 -5 -5 -5 16 62 -5 -5 ...## $ credit_history_points : num -5 -6 -6 -6 -79 -6 47 -6 -6 47 ...## $ purpose_points : num -30 65 34 34 -12 34 65 -10 -30 65 ...## $ amount_points : num -34 -34 23 -3 -34 23 23 -3 -34 -34 ...## $ savings_points : num -18 -18 51 -9 51 51 -9 -18 -9 -9 ...## $ employment_duration_points : num -1 -1 15 -1 -17 9 -17 -1 -1 15 ...## $ installment_rate_points : num 10 30 30 -25 30 10 10 30 30 30 ...## $ personal_status_sex_points : num 9 9 -25 -13 9 9 9 9 9 9 ...## $ other_debtors_points : num -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 ...## $ age_points : num 11 31 11 -3 -29 -3 11 31 -3 -29 ...## $ other_installment_plans_points: num 8 8 8 8 -31 8 8 -31 8 8 ...## $ housing_points : num -34 -29 14 14 14 14 14 14 14 -29 ...## $ score : num 319 438 692 399 305 665 585 485 381 476 ...## - attr(*, &quot;.internal.selfref&quot;)=&lt;externalptr&gt; 9 模型稳定性监测稳定性指数(population stability index, PSI)是计算实际和预期的分值分布之间差异的一个衡量指标,$PSI=\sum_i{(A_i-E_i)\ln(A_i/E_i)}$。其计算过程见下表: psi 12345678psi&lt;-perf_psi( score = list(train = train_score, test = test_score), label = list(train = train$credit_risk, test = test$credit_risk), x_limits = c(250, 700), x_tick_break = 50, return_distr_dat = TRUE)psi$pic## $score 1psi$psi 10 拒绝推断 申请评分卡的模型开发过程中使用的数据实际上并不是从申请总体样本中随机选择的，而仅仅是从过去已经被接受的客户样本中选择的。因此，开发申请评分卡时将对被拒绝客户的状态进行推断并纳入模型开发数据集中，即拒绝推断过程。 拒绝推断的常用方法包括， 简单赋值法：人为指定被拒绝账户的标签 忽略被拒绝申请 所有被拒申请赋值为违约标签 按比例赋值，使得其坏客户率是通过样本的2~5倍以上 强化法：通过外推法确定拒绝账户的标签 简单强化法：使用通过客户开发的模型对被拒绝客户评分，将其中低分段赋予违约标签。使得拒绝客户的坏客户率为通过的2~5倍以上 模糊强化法：通过模型计算得到正常和违约概率。 打包强化法：先用开发的评分卡对被拒客户评分，然后指定每个分值区间的违约客户数量。 引用自《信用风险评分卡研究_基于SAS的开发与实施》↩ https://github.com/ShichenXie/shichenxie.github.io/blob/master/slide/20171115scorecard/index.Rmd↩]]></content>
      <categories>
        <category>评分卡</category>
      </categories>
      <tags>
        <tag>R语言</tag>
        <tag>评分卡</tag>
      </tags>
  </entry>
</search>
